package com.example.flink.job;

import com.example.flink.model.CleanProfile;
import com.example.flink.model.RawProfile;
import com.example.flink.kafka.SinkProfile;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.SerializationFeature;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import com.example.flink.config.TestConfig;
import org.apache.flink.api.common.typeinfo.Types;

import java.time.Instant;

// ì¹´í”„ì¹´ì—ì„œ ì›ë³¸ í”„ë¡œí•„ JSON ë°ì´í„°ë¥¼ ì½ì–´ì˜´
// ë‹¤ìŒ ê·œì¹™ìœ¼ë¡œ ì •ì œí•¨
// ìƒˆ ì¹´í”„ì¹´ í† í”½ì— ì •ì¬í•˜ëŠ” Job

public class CleanProfilesJob {
    //JSON ì§ë ¬í™”/ì—­ì§ë ¬í™” ìœ„í•œ ObjectMapper
    private static final ObjectMapper MAPPER = new ObjectMapper();

    public static void main(String[] args) throws Exception {
        // 1ï¸âƒ£ Flink ì‹¤í–‰ í™˜ê²½ ìƒì„±
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // 2ï¸âƒ£ ì„¤ì • íŒŒì¼ ë¡œë”© (src/main/resources/config.properties)
        final TestConfig config = new TestConfig();
        final String brokers  = config.getBrokers(); // ë¸Œë¡œì»¤ ì£¼ì†Œ ëª©ë¡
        final String srcTopic = config.getSourceTopic(); // ì›ë³¸ ë°ì´í„° í† í”½
        final String dstTopic = config.getSinkTopic(); // ì •ì œ ë°ì´í„° í† í”½
        final String groupId  = config.getGroupId(); // ì¹´í”„ì¹´ ì»¨ìŠˆë¨¸ ê·¸ë£¹ ID
        final String offsetReset = config.getOffsetReset(); // earliest or latest

        // earliest : í•´ë‹¹ Consumer Groupì´ ì•„ì§ ì½ì€ ìœ„ì¹˜(ì˜¤í”„ì…‹) ê¸°ë¡ì´ ì—†ì„ ë•Œ, í† í”½ì˜ ê°€ì¥ ì²˜ìŒ(ìµœì†Œ ì˜¤í”„ì…‹)ë¶€í„° ì½ê¸° ì‹œì‘
        // latest : í•´ë‹¹ Consumer Groupì´ ì•„ì§ ì½ì€ ìœ„ì¹˜ ê¸°ë¡ì´ ì—†ì„ ë•Œ, í˜„ì¬ ì‹œì  ì´í›„ì— ë“¤ì–´ì˜¤ëŠ” ìƒˆ ë©”ì‹œì§€ë¶€í„° ì½ê¸° ì‹œì‘

        // 3ï¸âƒ£ ì˜¤í”„ì…‹ ì´ˆê¸°í™” ë°©ì‹ ê²°ì • (ê¸°ë³¸ earliest)
        final OffsetsInitializer offsets =
                "latest".equalsIgnoreCase(offsetReset) ? OffsetsInitializer.latest() : OffsetsInitializer.earliest();

        // 4ï¸âƒ£ Kafkaì—ì„œ RawProfile JSON ë°ì´í„°ë¥¼ ì½ì–´ DataStream<RawProfile> ìƒì„±
        // SourceProfile ìœ í‹¸ì„ í†µí•´ JSON -> RawProfile POJO ìë™ ë§¤í•‘
        // ğŸ’¬ POJO (Plain Old Java Object) : íŠ¹ë³„í•œ ì œì•½ì´ë‚˜ ìƒì† ì—†ì´, ìˆœìˆ˜í•˜ê²Œ ë°ì´í„°ë¥¼ ë‹´ê¸° ìœ„í•œ ì¼ë°˜ ìë°” ê°ì²´
        DataStream<RawProfile> parsed = com.example.flink.kafka.SourceProfile.streamRawProfile(
                env, brokers, srcTopic, groupId, offsets);

        //earliestë¶€í„° RawProfileë¡œ ì½ê¸°
        //DataStream<RawProfile> parsed = com.example.flink.kafka.SourceProfile.streamRawProfileEarliest(env, brokers, srcTopic, groupId);

        // 5ï¸âƒ£ ë°ì´í„° ì •ì œ ë¡œì§ ì ìš© (MapFunction ì‚¬ìš©)
        DataStream<CleanProfile> cleaned = parsed
                .map((MapFunction<RawProfile, CleanProfile>) rp -> {
                    long now = Instant.now().toEpochMilli(); // ì •ì œ ì‹œê° ê¸°ë¡
                    return new CleanProfile(
                            rp.getEmail(),
                            maskName(rp.getName()), // ì´ë¦„ ë§ˆìŠ¤í‚¹
                            formatPhone(rp.getPhone()), // ì „í™”ë²ˆí˜¸ í¬ë§· ë³€í™˜
                            toYYMMDD(rp.getBirthDate()), // ìƒë…„ì›”ì¼ ë³€í™˜
                            trimAddress(rp.getAddress()), // ì£¼ì†Œ ì¶•ì•½
                            rp.getRole(),
                            rp.getRecordId(),
                            rp.getSourceSystem(),
                            rp.getCountry(),
                            now
                    );
                })
                .returns(CleanProfile.class); // ì •ì œëœ ë°ì´í„° ë°˜í™˜

        // 6ï¸âƒ£ CleanProfile ê°ì²´ë¥¼ JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”
        final ObjectMapper om = new ObjectMapper().disable(SerializationFeature.FAIL_ON_EMPTY_BEANS);

        DataStream<String> outJson = cleaned
                .map((MapFunction<CleanProfile, String>) om::writeValueAsString)
                .returns(Types.STRING);

        // 7ï¸âƒ£ Kafka Sink ìƒì„± -> ì •ì œ ë°ì´í„° í† í”½ìœ¼ë¡œ ì „ì†¡
        //outJson.sinkTo(SinkProfile.createKafkaSink(brokers, dstTopic));
        outJson
            .map(value -> Tuple2.of("myKey", value)) // Key ì§€ì •
                .returns(Types.TUPLE(Types.STRING, Types.STRING))
                .sinkTo(SinkProfile.createKafkaSinkWithKey(brokers, dstTopic));

        // 8ï¸âƒ£ Flink Job
        // ì—¬ê¸°ì„œ ì¹´í”„ì¹´ ì ì¬ë¨
        // ì •ì œ ë¡œì§ì´ ì ìš©ëœ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘
        // env ë‹¨ê³„ì—ì„œ ì§€ê¸ˆê¹Œì§€ ì„¤ì •í•œ ì†ŒìŠ¤, ë³€í™˜, ì‹±í¬ ì—°ì‚°ë“¤ì„ ì‹¤í–‰ ê³„íš í˜•íƒœë¡œ ìŒ“ì—¬ ìˆìŒ
        // execute : Flinkê°€ ì´ ì‹¤í–‰ ê³„íšì„ JobGraphë¡œ ë³€í™˜
        // í´ëŸ¬ìŠ¤í„°/ë¡œì»¬ í™˜ê²½ì— ì œì¶œ -> ë³‘ë ¬ë¡œ ì—°ì‚°(task) ì‹œì‘
        // ì´í›„ Kafka Sourceì—ì„œ ë°ì´í„°ë¥¼ ì½ê³  â†’ map ë³€í™˜(ì •ì œ ë¡œì§) â†’ Kafka Sinkì— ì“°ëŠ” íë¦„ì´ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ê³„ì† ë°˜ë³µ
        env.execute("Clean Profiles Job");
    }

    // ====== ìœ í‹¸ í•¨ìˆ˜ë“¤ ======

    // 1) ì´ë¦„ ë§ˆìŠ¤í‚¹: ì²« ê¸€ì + '*' + ë§ˆì§€ë§‰ ê¸€ì (2ê¸€ìë©´ ì•ê¸€ì+*)
    private static String maskName(String name) {
        if (name == null || name.isBlank()) return "";
        name = name.trim();
        if (name.length() == 1) return name;
        if (name.length() == 2) return name.charAt(0) + "*";
        return name.charAt(0) + "*" + name.substring(name.length() - 1);
    }

    // 2) ì „í™”ë²ˆí˜¸ í¬ë§·: ì•„ë¬´ ë¬¸ìë‚˜ ì œê±° â†’ êµ­ê°€ì½”ë“œ(+82)ë©´ 0ìœ¼ë¡œ ì¹˜í™˜ â†’ 3-4-4 í˜•íƒœ
    private static String formatPhone(String phone) {
        if (phone == null) return "";
        // ìˆ«ìì™€ '+'ë§Œ ë‚¨ê¹€
        String d = phone.replaceAll("[^0-9+]", "");
        // +82 â†’ 0 ì ‘ë‘ë¡œ ì¹˜í™˜ (+8210XXXX â†’ 010XXXX)
        if (d.startsWith("+82")) {
            d = "0" + d.substring(3);
        }
        // ë‚˜ë¨¸ì§€ ë¹„ìˆ«ì ì œê±°
        d = d.replaceAll("[^0-9]", "");
        // 11ìë¦¬(010xxxxxxxx) ê¸°ì¤€ ë¶„í• , ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ê°€ëŠ¥í•œ í•œ ì•ˆì „í•˜ê²Œ ë¶„í• 
        if (d.length() >= 11) {
            return d.substring(0, 3) + "-" + d.substring(3, 7) + "-" + d.substring(7, 11);
        } else if (d.length() == 10) { // êµ¬í˜• 10ìë¦¬ ì˜ˆì™¸ ì²˜ë¦¬
            return d.substring(0, 3) + "-" + d.substring(3, 6) + "-" + d.substring(6);
        } else if (d.length() > 3 && d.length() <= 8) {
            // ì„ì‹œ ë°ì´í„° ë“±: 3-ë‚˜ë¨¸ì§€ ë¶„í• 
            return d.substring(0, 3) + "-" + d.substring(3);
        }
        return d; // í¬ë§· ë¶ˆê°€ ì‹œ ì›ì‹œ ìˆ«ìì—´ ë°˜í™˜
    }

    // 3) ìƒë…„ì›”ì¼ â†’ YYMMDD (ì…ë ¥ì´ YYYY-MM-DD ë˜ëŠ” YYYYMMDD ê°€ì •)
    private static String toYYMMDD(String birthDate) {
        if (birthDate == null || birthDate.isBlank()) return "";
        String digits = birthDate.replaceAll("[^0-9]", "");
        if (digits.length() >= 8) {
            String yy = digits.substring(2, 4);
            String mm = digits.substring(4, 6);
            String dd = digits.substring(6, 8);
            return yy + mm + dd;
        }
        // ê¸¸ì´ê°€ ì• ë§¤í•˜ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return digits;
    }

    // 4) ì£¼ì†Œ: "â€¦êµ¬"ê°€ ìˆìœ¼ë©´ êµ¬ê¹Œì§€, ì—†ìœ¼ë©´ "â€¦ì‹œ"ê¹Œì§€ë§Œ ë‚¨ê¹€
    private static String trimAddress(String address) {
        if (address == null || address.isBlank()) return "";
        address = address.trim();
        int idxGu = address.indexOf('êµ¬');
        if (idxGu >= 0) return address.substring(0, idxGu + 1);
        int idxSi = address.indexOf('ì‹œ');
        if (idxSi >= 0) return address.substring(0, idxSi + 1);
        // ê·¸ë˜ë„ ì—†ìœ¼ë©´ ì²« ê³µë°± ì „ê¹Œì§€
        int sp = address.indexOf(' ');
        return sp > 0 ? address.substring(0, sp) : address;
    }
}
